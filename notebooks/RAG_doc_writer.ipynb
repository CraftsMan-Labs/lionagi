{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lionagi==0.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lionagi as li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_path = Path.cwd() / \"lionagi_data\"  # Path to the data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files from directory\n",
    "docs = li.load(\n",
    "    input_dir=data_path, \n",
    "    recursive=True, \n",
    "    required_exts=[\".py\"]\n",
    ")\n",
    "\n",
    "docs = [doc for doc in docs if len(doc.content) > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chunk\n",
    "# pile = li.chunk(docs=docs, chunk_size=2000, overlap=0.1)\n",
    "\n",
    "# # embed\n",
    "\n",
    "# embed_model = li.iModel(\n",
    "#     model=\"text-embedding-3-small\", \n",
    "#     provider=\"openai\",\n",
    "#     endpoint=\"embeddings\",\n",
    "#     interval_tokens=2_000_000,\n",
    "#     interval_requests=10_000,\n",
    "#     interval=60,\n",
    "#     # api_key = \"YOUR_API_KEY_HERE\" # Optional if you already put it in .env file\n",
    "# )\n",
    "\n",
    "# await pile.embed_pile(imodel=embed_model)\n",
    "\n",
    "# # save\n",
    "# pile.to_csv(\"lionagi_embedding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload pile from saved csv\n",
    "pile = li.pile(csv_file=\"lionagi_embedding.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "write a good API documentation for provided code, must use \n",
    "query engine to check meanings of related code concepts \n",
    "to accurately describe, for example if a name of a variable,\n",
    "function, class, or module is used but not present in context,\n",
    "- You MUST check with the query engine. \n",
    "- You MUST use extension at least ONCE. \n",
    "- You MUST make sure that documentation is accurate and detailed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lionagi.libs.sys_util import SysUtil\n",
    "SysUtil.check_import(\n",
    "    package_name=\"llama_index\", \n",
    "    module_name=\"core.postprocessor\",\n",
    "    import_name=\"LLMRerank\",\n",
    "    pip_name=\"llama-index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = pile.as_query_tool(\n",
    "    index_type = \"llama_index\",\n",
    "    query_type = \"query\",\n",
    "    name=\"qa_lionagi\",\n",
    "    guidance=\"Perform query to a QA bot with access to lionagi codebase\",\n",
    "    query_description=\"a term/phrase/question to lookup or a question to answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(await pile.query_pile(\"what is a branch in lionagi?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatting with model...\n",
      "Found action requests in model response. Processing actions...\n",
      "Actions processed!\n",
      "Analyzing action responses and generating answer...\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Directive successfully completed!\n"
     ]
    }
   ],
   "source": [
    "from PROMPTS import sys_prompt  # put your system prompt here\n",
    "\n",
    "model = li.iModel(\n",
    "    model=\"gpt-4o\",\n",
    "    provider=\"openai\",\n",
    "    interval_tokens=1_000_000,\n",
    "    interval_requests=1_000,\n",
    "    interval=60,\n",
    "    temperature=0.4,\n",
    ")\n",
    "\n",
    "branch = li.Branch(system=sys_prompt, tools=tools, imodel=model)\n",
    "\n",
    "form = await branch.direct(\n",
    "    instruction=instruction,\n",
    "    context=docs[249].content + docs[250].content,\n",
    "    allow_action=True,\n",
    "    allow_extension=True,\n",
    "    verbose=True,\n",
    "    max_extensions=2,\n",
    "    retries=3,  # sometimes the model may fail to generate a valid response or refuse to take actions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>role</th>\n",
       "      <th>content</th>\n",
       "      <th>metadata</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7fd8d6aa87fb753c6299c1d9369ff067</td>\n",
       "      <td>System</td>\n",
       "      <td>2024-08-02T18:07:57.807908</td>\n",
       "      <td>system</td>\n",
       "      <td>{'system_info': '\n",
       "you are a helpful assistant,...</td>\n",
       "      <td>{'last_updated': {'recipient': '2024-08-02T18:...</td>\n",
       "      <td>system</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ef14a65e710375a0c437d55c72ddbf1</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>2024-08-02T18:07:57.808698</td>\n",
       "      <td>user</td>\n",
       "      <td>{'instruction': '\n",
       "        ## Task Instructions...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-08-02T18:07:...</td>\n",
       "      <td>user</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5820d33e27018cbb8f3435bdd7aea919</td>\n",
       "      <td>AssistantResponse</td>\n",
       "      <td>2024-08-02T18:08:03.405651</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'assistant_response': '```json\n",
       "{\n",
       "    \"answer\"...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-08-02T18:08:...</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>af7d00816d464031c07f505c472df71e</td>\n",
       "      <td>ActionRequest</td>\n",
       "      <td>2024-08-02T18:08:03.407183</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'action_request': {'function': 'qa_lionagi', ...</td>\n",
       "      <td>{'last_updated': {'function': '2024-08-02T18:0...</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "      <td>898677341eaee8b6c0921a272e0846a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a98f3e68fcf4b00ed46d2b681ba8072c</td>\n",
       "      <td>ActionRequest</td>\n",
       "      <td>2024-08-02T18:08:03.407327</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'action_request': {'function': 'qa_lionagi', ...</td>\n",
       "      <td>{'last_updated': {'function': '2024-08-02T18:0...</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "      <td>898677341eaee8b6c0921a272e0846a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bc93bee5283d63c8cc2a17eb2ef5437a</td>\n",
       "      <td>ActionRequest</td>\n",
       "      <td>2024-08-02T18:08:03.407436</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'action_request': {'function': 'qa_lionagi', ...</td>\n",
       "      <td>{'last_updated': {'function': '2024-08-02T18:0...</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "      <td>898677341eaee8b6c0921a272e0846a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30882315c0adafa191169a02e3c585f2</td>\n",
       "      <td>ActionRequest</td>\n",
       "      <td>2024-08-02T18:08:03.407517</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'action_request': {'function': 'qa_lionagi', ...</td>\n",
       "      <td>{'last_updated': {'function': '2024-08-02T18:0...</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "      <td>898677341eaee8b6c0921a272e0846a5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>d62f006d73a993ad4d801341faf4724b</td>\n",
       "      <td>ActionResponse</td>\n",
       "      <td>2024-08-02T18:08:05.566842</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'action_response': {'function': 'qa_lionagi',...</td>\n",
       "      <td>{'last_updated': {'function': '2024-08-02T18:0...</td>\n",
       "      <td>898677341eaee8b6c0921a272e0846a5</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>f62eeeacc0717752407e35adc65958a6</td>\n",
       "      <td>ActionResponse</td>\n",
       "      <td>2024-08-02T18:08:05.567179</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'action_response': {'function': 'qa_lionagi',...</td>\n",
       "      <td>{'last_updated': {'function': '2024-08-02T18:0...</td>\n",
       "      <td>898677341eaee8b6c0921a272e0846a5</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>930b879cf0ea1bcf9324f4be7a3a15a6</td>\n",
       "      <td>ActionResponse</td>\n",
       "      <td>2024-08-02T18:08:05.567276</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'action_response': {'function': 'qa_lionagi',...</td>\n",
       "      <td>{'last_updated': {'function': '2024-08-02T18:0...</td>\n",
       "      <td>898677341eaee8b6c0921a272e0846a5</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00611f4f5b90aa1a7f2491a85261edb5</td>\n",
       "      <td>ActionResponse</td>\n",
       "      <td>2024-08-02T18:08:05.567362</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'action_response': {'function': 'qa_lionagi',...</td>\n",
       "      <td>{'last_updated': {'function': '2024-08-02T18:0...</td>\n",
       "      <td>898677341eaee8b6c0921a272e0846a5</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>71365c476d4845d0f3f221e7d1c6b93e</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>2024-08-02T18:08:05.567788</td>\n",
       "      <td>user</td>\n",
       "      <td>{'instruction': 'please provide final answer b...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-08-02T18:08:...</td>\n",
       "      <td>user</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4d4a034cccd1226916d5f277100e7101</td>\n",
       "      <td>AssistantResponse</td>\n",
       "      <td>2024-08-02T18:08:19.480936</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'assistant_response': '### Class: `iModel`\n",
       "\n",
       "*...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-08-02T18:08:...</td>\n",
       "      <td>24ccee67652ffa3c7d23f43aa38d89bd</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               ln_id       message_type  \\\n",
       "0   7fd8d6aa87fb753c6299c1d9369ff067             System   \n",
       "1   9ef14a65e710375a0c437d55c72ddbf1        Instruction   \n",
       "2   5820d33e27018cbb8f3435bdd7aea919  AssistantResponse   \n",
       "3   af7d00816d464031c07f505c472df71e      ActionRequest   \n",
       "4   a98f3e68fcf4b00ed46d2b681ba8072c      ActionRequest   \n",
       "5   bc93bee5283d63c8cc2a17eb2ef5437a      ActionRequest   \n",
       "6   30882315c0adafa191169a02e3c585f2      ActionRequest   \n",
       "7   d62f006d73a993ad4d801341faf4724b     ActionResponse   \n",
       "8   f62eeeacc0717752407e35adc65958a6     ActionResponse   \n",
       "9   930b879cf0ea1bcf9324f4be7a3a15a6     ActionResponse   \n",
       "10  00611f4f5b90aa1a7f2491a85261edb5     ActionResponse   \n",
       "11  71365c476d4845d0f3f221e7d1c6b93e        Instruction   \n",
       "12  4d4a034cccd1226916d5f277100e7101  AssistantResponse   \n",
       "\n",
       "                     timestamp       role  \\\n",
       "0   2024-08-02T18:07:57.807908     system   \n",
       "1   2024-08-02T18:07:57.808698       user   \n",
       "2   2024-08-02T18:08:03.405651  assistant   \n",
       "3   2024-08-02T18:08:03.407183  assistant   \n",
       "4   2024-08-02T18:08:03.407327  assistant   \n",
       "5   2024-08-02T18:08:03.407436  assistant   \n",
       "6   2024-08-02T18:08:03.407517  assistant   \n",
       "7   2024-08-02T18:08:05.566842  assistant   \n",
       "8   2024-08-02T18:08:05.567179  assistant   \n",
       "9   2024-08-02T18:08:05.567276  assistant   \n",
       "10  2024-08-02T18:08:05.567362  assistant   \n",
       "11  2024-08-02T18:08:05.567788       user   \n",
       "12  2024-08-02T18:08:19.480936  assistant   \n",
       "\n",
       "                                              content  \\\n",
       "0   {'system_info': '\n",
       "you are a helpful assistant,...   \n",
       "1   {'instruction': '\n",
       "        ## Task Instructions...   \n",
       "2   {'assistant_response': '```json\n",
       "{\n",
       "    \"answer\"...   \n",
       "3   {'action_request': {'function': 'qa_lionagi', ...   \n",
       "4   {'action_request': {'function': 'qa_lionagi', ...   \n",
       "5   {'action_request': {'function': 'qa_lionagi', ...   \n",
       "6   {'action_request': {'function': 'qa_lionagi', ...   \n",
       "7   {'action_response': {'function': 'qa_lionagi',...   \n",
       "8   {'action_response': {'function': 'qa_lionagi',...   \n",
       "9   {'action_response': {'function': 'qa_lionagi',...   \n",
       "10  {'action_response': {'function': 'qa_lionagi',...   \n",
       "11  {'instruction': 'please provide final answer b...   \n",
       "12  {'assistant_response': '### Class: `iModel`\n",
       "\n",
       "*...   \n",
       "\n",
       "                                             metadata  \\\n",
       "0   {'last_updated': {'recipient': '2024-08-02T18:...   \n",
       "1   {'last_updated': {'sender': '2024-08-02T18:07:...   \n",
       "2   {'last_updated': {'sender': '2024-08-02T18:08:...   \n",
       "3   {'last_updated': {'function': '2024-08-02T18:0...   \n",
       "4   {'last_updated': {'function': '2024-08-02T18:0...   \n",
       "5   {'last_updated': {'function': '2024-08-02T18:0...   \n",
       "6   {'last_updated': {'function': '2024-08-02T18:0...   \n",
       "7   {'last_updated': {'function': '2024-08-02T18:0...   \n",
       "8   {'last_updated': {'function': '2024-08-02T18:0...   \n",
       "9   {'last_updated': {'function': '2024-08-02T18:0...   \n",
       "10  {'last_updated': {'function': '2024-08-02T18:0...   \n",
       "11  {'last_updated': {'sender': '2024-08-02T18:08:...   \n",
       "12  {'last_updated': {'sender': '2024-08-02T18:08:...   \n",
       "\n",
       "                              sender                         recipient  \n",
       "0                             system  24ccee67652ffa3c7d23f43aa38d89bd  \n",
       "1                               user  24ccee67652ffa3c7d23f43aa38d89bd  \n",
       "2   24ccee67652ffa3c7d23f43aa38d89bd                              user  \n",
       "3   24ccee67652ffa3c7d23f43aa38d89bd  898677341eaee8b6c0921a272e0846a5  \n",
       "4   24ccee67652ffa3c7d23f43aa38d89bd  898677341eaee8b6c0921a272e0846a5  \n",
       "5   24ccee67652ffa3c7d23f43aa38d89bd  898677341eaee8b6c0921a272e0846a5  \n",
       "6   24ccee67652ffa3c7d23f43aa38d89bd  898677341eaee8b6c0921a272e0846a5  \n",
       "7   898677341eaee8b6c0921a272e0846a5  24ccee67652ffa3c7d23f43aa38d89bd  \n",
       "8   898677341eaee8b6c0921a272e0846a5  24ccee67652ffa3c7d23f43aa38d89bd  \n",
       "9   898677341eaee8b6c0921a272e0846a5  24ccee67652ffa3c7d23f43aa38d89bd  \n",
       "10  898677341eaee8b6c0921a272e0846a5  24ccee67652ffa3c7d23f43aa38d89bd  \n",
       "11                              user  24ccee67652ffa3c7d23f43aa38d89bd  \n",
       "12  24ccee67652ffa3c7d23f43aa38d89bd                              user  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**task**: \n",
       " Follow the prompt and provide the necessary output.\n",
       "- Additional instruction: \n",
       "write a good API documentation for provided code, must use \n",
       "query engine to check meanings of related code concepts \n",
       "to accurately describe, for example if a name of a variable,\n",
       "function, class, or module is used but not present in context,\n",
       "- You MUST check with the query engine. \n",
       "- You MUST use extension at least ONCE. \n",
       "- You MUST make sure that documentation is accurate and detailed.\n",
       "\n",
       "- Additional context: import asyncio\n",
       "import numpy as np\n",
       "from typing import Callable\n",
       "from lion_core.libs import to_list, nget\n",
       "from lionagi.os.operator.imodel.imodel import iModel\n",
       "\n",
       "async def compute_perplexity(\n",
       "    imodel: iModel,\n",
       "    initial_context: str = None,\n",
       "    tokens: list[str] = None,\n",
       "    system_msg: str = None,\n",
       "    n_samples: int = 1,  # number of samples used for the computation\n",
       "    use_residue: bool = True,  # whether to use residue for the last sample\n",
       "    **kwargs,  # additional arguments for the model\n",
       ") -> tuple[list[str], float]:\n",
       "    tasks = []\n",
       "    context = initial_context or \"\"\n",
       "    n_samples = n_samples or len(tokens)\n",
       "    sample_token_len, residue = divmod(len(tokens), n_samples)\n",
       "    samples = []\n",
       "    if n_samples == 1:\n",
       "        samples = [tokens]\n",
       "    else:\n",
       "        samples = [tokens[: (i + 1) * sample_token_len] for i in range(n_samples)]\n",
       "        if use_residue and residue != 0:\n",
       "            samples.append(tokens[-residue:])\n",
       "    sampless = [context + \" \".join(sample) for sample in samples]\n",
       "    for sample in sampless:\n",
       "        messages = [{\"role\": \"system\", \"content\": system_msg}] if system_msg else []\n",
       "        messages.append(\n",
       "            {\"role\": \"user\", \"content\": sample},\n",
       "        )\n",
       "        task = asyncio.create_task(\n",
       "            imodel.chat_completion(\n",
       "                messages=messages,\n",
       "                logprobs=True,\n",
       "                max_tokens=sample_token_len,\n",
       "                **kwargs,\n",
       "            )\n",
       "        )\n",
       "        tasks.append(task)\n",
       "    results = await asyncio.gather(*tasks)  # result is (p..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**reason**: \n",
       " Let's think step by step. To provide accurate and detailed API documentation, it is essential to understand the specific meanings of key terms, functions, and classes used in the provided code. Therefore, querying the meanings of 'perplexity' in NLP, and the functions 'nget', 'to_list', and the class 'iModel' will help ensure the documentation is precise and comprehensive."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**actions**: \n",
       " \n",
       " \n",
       "1. **qa_lionagi**(query: What is the meaning of 'perplexity' in the context of natural language processing (NLP)?), \n",
       " \n",
       "2. **qa_lionagi**(query: What does the function 'nget' from 'lion_core.libs' do?), \n",
       " \n",
       "3. **qa_lionagi**(query: What does the function 'to_list' from 'lion_core.libs' do?), \n",
       " \n",
       "4. **qa_lionagi**(query: What does the class 'iModel' from 'lionagi.os.operator.imodel.imodel' represent?)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**action_required**: True"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**extension_required**: None"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**action_response**: \n",
       " \n",
       " \n",
       "1. **qa_lionagi**(query: What does the function 'nget' from 'lion_core.libs' do?) \n",
       " \n",
       " The function 'nget' retrieves a value from a nested list or dictionary structure using specified indices. If the target location cannot be reached or does not exist, it returns a specified default value or raises a LookupError if no default is provided. The indices can be integers for lists and strings for dictionaries., \n",
       " \n",
       "2. **qa_lionagi**(query: What does the function 'to_list' from 'lion_core.libs' do?) \n",
       " \n",
       " The function 'to_list' from 'lion_core.libs' converts the given input into a list., \n",
       " \n",
       "3. **qa_lionagi**(query: What does the class 'iModel' from 'lionagi.os.operator.imodel.imodel' represent?) \n",
       " \n",
       " The class 'iModel' from 'lionagi.os.operator.imodel.imodel' represents a model interface used for defining the structure and behavior of models within the 'lionagi' system., \n",
       " \n",
       "4. **qa_lionagi**(query: What does the class 'iModel' from 'lionagi.os.operator.imodel.imodel' represent?) \n",
       " \n",
       " The class 'iModel' from 'lionagi.os.operator.imodel.imodel' represents a model interface used for defining the structure and behavior of models within the 'lionagi' system., \n",
       " \n",
       "5. **qa_lionagi**(query: What is the meaning of 'perplexity' in the context of natural language processing (NLP)?) \n",
       " \n",
       " In the context of natural language processing (NLP), 'perplexity' is a measurement used to evaluate the performance of a language model. It quantifies how well a probability distribution or probability model predicts a sample. A lower perplexity indicates that the model is better at predicting the sample, meaning it is more confident in its predictions. Essentially, perplexity measures the uncertainty of the model when it comes to predicting the next word in a sequence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**action_performed**: True"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**available_tools**: ['qa_lionagi']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**answer**: \n",
       " ### Class: `iModel`\n",
       "\n",
       "**Description**:\n",
       "The `iModel` class represents a model interface used for defining the structure and behavior of models within the 'lionagi' system.\n",
       "\n",
       "### Method: `compute_perplexity`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "async def compute_perplexity(\n",
       "    imodel: iModel,\n",
       "    initial_context: str = None,\n",
       "    tokens: list[str] = None,\n",
       "    system_msg: str = None,\n",
       "    n_samples: int = 1,\n",
       "    use_residue: bool = True,\n",
       "    **kwargs\n",
       ") -> tuple[list[str], float]:\n",
       "```\n",
       "\n",
       "**Parameters**:\n",
       "- `imodel` (iModel): The model interface used for chat completion.\n",
       "- `initial_context` (str, optional): The initial context string. Defaults to `None`.\n",
       "- `tokens` (list[str], optional): List of tokens to be used. Defaults to `None`.\n",
       "- `system_msg` (str, optional): System message to be included. Defaults to `None`.\n",
       "- `n_samples` (int, optional): Number of samples used for the computation. Defaults to `1`.\n",
       "- `use_residue` (bool, optional): Whether to use residue for the last sample. Defaults to `True`.\n",
       "- `**kwargs`: Additional arguments for the model.\n",
       "\n",
       "**Return Values**:\n",
       "- `tuple[list[str], float]`: A tuple containing a list of strings and a float value representing the computed perplexity.\n",
       "\n",
       "**Exceptions Raised**:\n",
       "- None explicitly raised.\n",
       "\n",
       "**Usage Examples**:\n",
       "```python\n",
       "# Example usage of compute_perplexity\n",
       "import asyncio\n",
       "from lionagi.os.operator.imodel.imodel import iModel\n",
       "\n",
       "async def main():\n",
       "    imodel = iModel()\n",
       "    tokens = [\"example\", \"tokens\", \"for\", \"perplexity\"]\n",
       "    result = await compute_perplexity(imodel, tokens=tokens)\n",
       "    print(result)\n",
       "\n",
       "asyncio.run(main())\n",
       "```\n",
       "\n",
       "### Method: `select_by_pplex`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "def select_by_pplex(\n",
       "    ranked_items: list,\n",
       "    target_compression_ratio: float,\n",
       "    original_length: int,\n",
       "    tokenizer: Callable,\n",
       "    min_pplex: float\n",
       ") -> list:\n",
       "```\n",
       "\n",
       "**Parameters**:\n",
       "- `ranked_items` (list): List of items ranked by perplexity.\n",
       "- `target_compression_ratio` (float): Desired compression ratio.\n",
       "- `original_length` (int): Original length of the items.\n",
       "- `tokenizer` (Callable): Function to tokenize the items.\n",
       "- `min_pplex` (float): Minimum perplexity threshold.\n",
       "\n",
       "**Return Values**:\n",
       "- `list`: List of selected items based on the perplexity and compression ratio.\n",
       "\n",
       "**Exceptions Raised**:\n",
       "- None explicitly raised.\n",
       "\n",
       "**Usage Examples**:\n",
       "```python\n",
       "# Example usage of select_by_pplex\n",
       "ranked_items = [(\"item1\", {\"perplexity\": 10}), (\"item2\", {\"perplexity\": 5})]\n",
       "target_compression_ratio = 0.5\n",
       "original_length = 100\n",
       "tokenizer = lambda x: x.split()\n",
       "\n",
       "selected_items = select_by_pplex(ranked_items, target_compression_ratio, original_length, tokenizer, min_pplex=3)\n",
       "print(selected_items)\n",
       "```\n",
       "\n",
       "### Concepts Used\n",
       "\n",
       "- **Perplexity**: In the context of natural language processing (NLP), 'perplexity' is a measurement used to evaluate the performance of a language model. It quantifies how well a probability distribution or probability model predicts a sample. A lower perplexity indicates that the model is better at predicting the sample, meaning it is more confident in its predictions. Essentially, perplexity measures the uncertainty of the model when it comes to predicting the next word in a sequence.\n",
       "\n",
       "- **nget**: The function 'nget' retrieves a value from a nested list or dictionary structure using specified indices. If the target location cannot be reached or does not exist, it returns a specified default value or raises a LookupError if no default is provided. The indices can be integers for lists and strings for dictionaries.\n",
       "\n",
       "- **to_list**: The function 'to_list' from 'lion_core.libs' converts the given input into a list."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "form.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit = \"\"\"\n",
    "provide documentation only: final documentation in md \n",
    "format of the module of interest, do not include other \n",
    "fields do not present in JSON format, only markdown format \n",
    "you asked a lot of good questions and got plenty answers, \n",
    "please integrate your conversation, be a lot more technical, you will \n",
    "be rewarded with 500 dollars for great work, and \n",
    "punished for subpar work, take a deep breath, you can do it\n",
    "\"\"\"\n",
    "\n",
    "final_output = await branch.chat(instruction=edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Module Documentation\n",
       "\n",
       "### Class: `iModel`\n",
       "\n",
       "**Description**:\n",
       "The `iModel` class represents a model interface used for defining the structure and behavior of models within the 'lionagi' system. It is designed to facilitate interactions with various language models, providing methods for tasks such as chat completion and perplexity computation.\n",
       "\n",
       "### Method: `compute_perplexity`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "async def compute_perplexity(\n",
       "    imodel: iModel,\n",
       "    initial_context: str = None,\n",
       "    tokens: list[str] = None,\n",
       "    system_msg: str = None,\n",
       "    n_samples: int = 1,\n",
       "    use_residue: bool = True,\n",
       "    **kwargs\n",
       ") -> tuple[list[str], float]:\n",
       "```\n",
       "\n",
       "**Parameters**:\n",
       "- `imodel` (`iModel`): The model interface used for chat completion.\n",
       "- `initial_context` (`str`, optional): The initial context string. Defaults to `None`.\n",
       "- `tokens` (`list[str]`, optional): List of tokens to be used. Defaults to `None`.\n",
       "- `system_msg` (`str`, optional): System message to be included. Defaults to `None`.\n",
       "- `n_samples` (`int`, optional): Number of samples used for the computation. Defaults to `1`.\n",
       "- `use_residue` (`bool`, optional): Whether to use residue for the last sample. Defaults to `True`.\n",
       "- `**kwargs`: Additional arguments for the model.\n",
       "\n",
       "**Return Values**:\n",
       "- `tuple[list[str], float]`: A tuple containing a list of strings and a float value representing the computed perplexity.\n",
       "\n",
       "**Exceptions Raised**:\n",
       "- None explicitly raised.\n",
       "\n",
       "**Usage Examples**:\n",
       "```python\n",
       "import asyncio\n",
       "from lionagi.os.operator.imodel.imodel import iModel\n",
       "\n",
       "async def main():\n",
       "    imodel = iModel()\n",
       "    tokens = [\"example\", \"tokens\", \"for\", \"perplexity\"]\n",
       "    result = await compute_perplexity(imodel, tokens=tokens)\n",
       "    print(result)\n",
       "\n",
       "asyncio.run(main())\n",
       "```\n",
       "\n",
       "**Detailed Description**:\n",
       "The `compute_perplexity` function computes the perplexity of a given set of tokens using the provided `iModel` instance. Perplexity is a measurement used to evaluate the performance of a language model, quantifying how well the model predicts the given tokens. A lower perplexity indicates better performance.\n",
       "\n",
       "The function creates multiple samples from the provided tokens and computes the perplexity for each sample. The results are aggregated to provide the final perplexity score.\n",
       "\n",
       "### Method: `select_by_pplex`\n",
       "\n",
       "**Signature**:\n",
       "```python\n",
       "def select_by_pplex(\n",
       "    ranked_items: list,\n",
       "    target_compression_ratio: float,\n",
       "    original_length: int,\n",
       "    tokenizer: Callable,\n",
       "    min_pplex: float\n",
       ") -> list:\n",
       "```\n",
       "\n",
       "**Parameters**:\n",
       "- `ranked_items` (`list`): List of items ranked by perplexity.\n",
       "- `target_compression_ratio` (`float`): Desired compression ratio.\n",
       "- `original_length` (`int`): Original length of the items.\n",
       "- `tokenizer` (`Callable`): Function to tokenize the items.\n",
       "- `min_pplex` (`float`): Minimum perplexity threshold.\n",
       "\n",
       "**Return Values**:\n",
       "- `list`: List of selected items based on the perplexity and compression ratio.\n",
       "\n",
       "**Exceptions Raised**:\n",
       "- None explicitly raised.\n",
       "\n",
       "**Usage Examples**:\n",
       "```python\n",
       "ranked_items = [(\"item1\", {\"perplexity\": 10}), (\"item2\", {\"perplexity\": 5})]\n",
       "target_compression_ratio = 0.5\n",
       "original_length = 100\n",
       "tokenizer = lambda x: x.split()\n",
       "\n",
       "selected_items = select_by_pplex(ranked_items, target_compression_ratio, original_length, tokenizer, min_pplex=3)\n",
       "print(selected_items)\n",
       "```\n",
       "\n",
       "**Detailed Description**:\n",
       "The `select_by_pplex` function selects items from a list of ranked items based on their perplexity scores and the desired compression ratio. The function iterates through the ranked items, tokenizes them, and selects items until the desired length is reached. Items with perplexity scores below the minimum threshold are ignored.\n",
       "\n",
       "### Concepts Used\n",
       "\n",
       "**Perplexity**:\n",
       "In the context of natural language processing (NLP), 'perplexity' is a measurement used to evaluate the performance of a language model. It quantifies how well a probability distribution or probability model predicts a sample. A lower perplexity indicates that the model is better at predicting the sample, meaning it is more confident in its predictions. Essentially, perplexity measures the uncertainty of the model when it comes to predicting the next word in a sequence.\n",
       "\n",
       "**nget**:\n",
       "The function 'nget' retrieves a value from a nested list or dictionary structure using specified indices. If the target location cannot be reached or does not exist, it returns a specified default value or raises a LookupError if no default is provided. The indices can be integers for lists and strings for dictionaries.\n",
       "\n",
       "**to_list**:\n",
       "The function 'to_list' from 'lion_core.libs' converts the given input into a list. This is useful for ensuring that the input is in a consistent format for further processing."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check extension forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(form, \"extension_forms\"):\n",
    "    for i in form.extension_forms:\n",
    "        i.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The task invoked query engine 4 times.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The function 'to_list' from 'lion_core.libs' converts the given input into a list."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The class 'iModel' from 'lionagi.os.operator.imodel.imodel' represents a model interface used for defining the structure and behavior of models within the 'lionagi' system."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The function 'nget' retrieves a value from a nested list or dictionary structure using specified indices. If the target location cannot be reached or does not exist, it returns a specified default value or raises a LookupError if no default is provided. The indices can be integers for lists and strings for dictionaries."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "In the context of natural language processing (NLP), 'perplexity' is a measurement used to evaluate the performance of a language model. It quantifies how well a probability distribution or probability model predicts a sample. A lower perplexity indicates that the model is better at predicting the sample, meaning it is more confident in its predictions. Essentially, perplexity measures the uncertainty of the model when it comes to predicting the next word in a sequence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"The task invoked query engine {len(pile.query_response)} times.\")\n",
    "\n",
    "for i in pile.query_response:\n",
    "    display(Markdown(i.response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
