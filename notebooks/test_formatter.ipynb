{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "here = Path.cwd().parent\n",
    "sys.path.append(str(here))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Class: iModel\n",
    "Description: The iModel class represents a model interface used for defining the structure and behavior of models within the 'lionagi' system. It is designed to facilitate interactions with various language models, providing methods for tasks such as chat completion and perplexity computation.\n",
    "\n",
    "Method: compute_perplexity\n",
    "Signature:\n",
    "\n",
    "async def compute_perplexity(\n",
    "    imodel: iModel,\n",
    "    initial_context: str = None,\n",
    "    tokens: list[str] = None,\n",
    "    system_msg: str = None,\n",
    "    n_samples: int = 1,\n",
    "    use_residue: bool = True,\n",
    "    **kwargs\n",
    ") -> tuple[list[str], float]:\n",
    "Parameters:\n",
    "\n",
    "imodel (iModel): The model interface used for chat completion.\n",
    "initial_context (str, optional): The initial context string. Defaults to None.\n",
    "tokens (list[str], optional): List of tokens to be used. Defaults to None.\n",
    "system_msg (str, optional): System message to be included. Defaults to None.\n",
    "n_samples (int, optional): Number of samples used for the computation. Defaults to 1.\n",
    "use_residue (bool, optional): Whether to use residue for the last sample. Defaults to True.\n",
    "**kwargs: Additional arguments for the model.\n",
    "Return Values:\n",
    "\n",
    "tuple[list[str], float]: A tuple containing a list of strings and a float value representing the computed perplexity.\n",
    "Exceptions Raised:\n",
    "\n",
    "None explicitly raised.\n",
    "Usage Examples:\n",
    "\n",
    "import asyncio\n",
    "from lionagi.os.operator.imodel.imodel import iModel\n",
    "\n",
    "async def main():\n",
    "    imodel = iModel()\n",
    "    tokens = [\"example\", \"tokens\", \"for\", \"perplexity\"]\n",
    "    result = await compute_perplexity(imodel, tokens=tokens)\n",
    "    print(result)\n",
    "\n",
    "asyncio.run(main())\n",
    "Detailed Description: The compute_perplexity function computes the perplexity of a given set of tokens using the provided iModel instance. Perplexity is a measurement used to evaluate the performance of a language model, quantifying how well the model predicts the given tokens. A lower perplexity indicates better performance.\n",
    "\n",
    "The function creates multiple samples from the provided tokens and computes the perplexity for each sample. The results are aggregated to provide the final perplexity score.\n",
    "\n",
    "Method: select_by_pplex\n",
    "Signature:\n",
    "\n",
    "def select_by_pplex(\n",
    "    ranked_items: list,\n",
    "    target_compression_ratio: float,\n",
    "    original_length: int,\n",
    "    tokenizer: Callable,\n",
    "    min_pplex: float\n",
    ") -> list:\n",
    "Parameters:\n",
    "\n",
    "ranked_items (list): List of items ranked by perplexity.\n",
    "target_compression_ratio (float): Desired compression ratio.\n",
    "original_length (int): Original length of the items.\n",
    "tokenizer (Callable): Function to tokenize the items.\n",
    "min_pplex (float): Minimum perplexity threshold.\n",
    "Return Values:\n",
    "\n",
    "list: List of selected items based on the perplexity and compression ratio.\n",
    "Exceptions Raised:\n",
    "\n",
    "None explicitly raised.\n",
    "Usage Examples:\n",
    "\n",
    "ranked_items = [(\"item1\", {\"perplexity\": 10}), (\"item2\", {\"perplexity\": 5})]\n",
    "target_compression_ratio = 0.5\n",
    "original_length = 100\n",
    "tokenizer = lambda x: x.split()\n",
    "\n",
    "selected_items = select_by_pplex(ranked_items, target_compression_ratio, original_length, tokenizer, min_pplex=3)\n",
    "print(selected_items)\n",
    "Detailed Description: The select_by_pplex function selects items from a list of ranked items based on their perplexity scores and the desired compression ratio. The function iterates through the ranked items, tokenizes them, and selects items until the desired length is reached. Items with perplexity scores below the minimum threshold are ignored.\n",
    "\n",
    "Concepts Used\n",
    "Perplexity: In the context of natural language processing (NLP), 'perplexity' is a measurement used to evaluate the performance of a language model. It quantifies how well a probability distribution or probability model predicts a sample. A lower perplexity indicates that the model is better at predicting the sample, meaning it is more confident in its predictions. Essentially, perplexity measures the uncertainty of the model when it comes to predicting the next word in a sequence.\n",
    "\n",
    "nget: The function 'nget' retrieves a value from a nested list or dictionary structure using specified indices. If the target location cannot be reached or does not exist, it returns a specified default value or raises a LookupError if no default is provided. The indices can be integers for lists and strings for dictionaries.\n",
    "\n",
    "to_list: The function 'to_list' from 'lion_core.libs' converts the given input into a list. This is useful for ensuring that the input is in a consistent format for further processing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatting with model...\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Directive successfully completed!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**task**: \n",
       " Follow the prompt and provide the necessary output.\n",
       "- Additional instruction: please very very detail devaluate the documentation using various criteria in your knowledge\n",
       "- Additional context: \n",
       "Class: iModel\n",
       "Description: The iModel class represents a model interface used for defining the structure and behavior of models within the 'lionagi' system. It is designed to facilitate interactions with various language models, providing methods for tasks such as chat completion and perplexity computation.\n",
       "\n",
       "Method: compute_perplexity\n",
       "Signature:\n",
       "\n",
       "async def compute_perplexity(\n",
       "    imodel: iModel,\n",
       "    initial_context: str = None,\n",
       "    tokens: list[str] = None,\n",
       "    system_msg: str = None,\n",
       "    n_samples: int = 1,\n",
       "    use_residue: bool = True,\n",
       "    **kwargs\n",
       ") -> tuple[list[str], float]:\n",
       "Parameters:\n",
       "\n",
       "imodel (iModel): The model interface used for chat completion.\n",
       "initial_context (str, optional): The initial context string. Defaults to None.\n",
       "tokens (list[str], optional): List of tokens to be used. Defaults to None.\n",
       "system_msg (str, optional): System message to be included. Defaults to None.\n",
       "n_samples (int, optional): Number of samples used for the computation. Defaults to 1.\n",
       "use_residue (bool, optional): Whether to use residue for the last sample. Defaults to True.\n",
       "**kwargs: Additional arguments for the model.\n",
       "Return Values:\n",
       "\n",
       "tuple[list[str], float]: A tuple containing a list of strings and a float value representing the computed perplexity.\n",
       "Exceptions Raised:\n",
       "\n",
       "None explicitly raised.\n",
       "Usage Examples:\n",
       "\n",
       "import asyncio\n",
       "from lionagi.os.operator.imodel.imodel import iModel\n",
       "\n",
       "async def main():\n",
       "    imodel = iModel()\n",
       "    tokens = [\"example\", \"tokens\", \"for\", \"perplexity\"]\n",
       "    result = await compute_perplexity(imodel, tokens=tokens)\n",
       "    print(result)\n",
       "\n",
       "asyncio.run(main())\n",
       "Detailed Description: The compute_perplexity function computes the perplexity of a given set of tokens using the provided iModel instance. Perplexity is a measurement used to evaluate the performance of a language model, quantif..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**confidence_score**: 0.85"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**reason**: \n",
       " Let's think step by step. The provided documentation for the iModel class and its methods 'compute_perplexity' and 'select_by_pplex' is quite detailed, but there are areas where it could be improved for better clarity and comprehensiveness. Here is a detailed evaluation based on various criteria."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**extension_required**: False"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**selection**: good"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**answer**: \n",
       " Let's think step by step. The provided documentation for the iModel class and its methods 'compute_perplexity' and 'select_by_pplex' is quite detailed, but there are areas where it could be improved for better clarity and comprehensiveness. Here is a detailed evaluation based on various criteria:\n",
       "\n",
       "1. **Clarity**:\n",
       "    - **Class Description**: The description of the iModel class is clear and provides a good understanding of its purpose within the 'lionagi' system.\n",
       "    - **Method Descriptions**: The descriptions of the methods are generally clear, but could benefit from more detailed explanations of certain parameters and their implications.\n",
       "\n",
       "2. **Completeness**:\n",
       "    - **Parameters**: All parameters are listed for each method, but some parameters, like **kwargs, could be better explained.\n",
       "    - **Return Values**: The return values are described, but examples of the structure of the returned tuple for 'compute_perplexity' and the list for 'select_by_pplex' would be helpful.\n",
       "    - **Exceptions**: It is stated that no exceptions are explicitly raised, but it would be beneficial to mention potential exceptions that could occur during execution (e.g., TypeErrors, ValueErrors).\n",
       "\n",
       "3. **Examples**:\n",
       "    - **Usage Examples**: The provided examples are useful, but they could be expanded to cover more scenarios, such as different combinations of parameters.\n",
       "\n",
       "4. **Technical Accuracy**:\n",
       "    - The technical details provided seem accurate, but without access to the actual code, it's difficult to verify the implementation specifics.\n",
       "\n",
       "5. **Readability**:\n",
       "    - The documentation is generally readable, but could be improved by breaking down complex sentences and adding more bullet points or subheadings for easier navigation.\n",
       "\n",
       "6. **Consistency**:\n",
       "    - The documentation is consistent in its format and style, which is good for readability and understanding.\n",
       "\n",
       "7. **Context**:\n",
       "    - **Concepts Used**: The explanation of 'perplexity' is clear and provides good context for understanding the methods. However, the functions 'nget' and 'to_list' are mentioned without clear context or examples of how they relate to the iModel class.\n",
       "\n",
       "8. **Additional Information**:\n",
       "    - There is no mention of the performance implications or computational complexity of the methods, which could be important for users to know.\n",
       "\n",
       "In summary, while the documentation is quite detailed and covers many aspects of the iModel class and its methods, it could be improved by providing more detailed explanations of certain parameters, additional usage examples, and information on potential exceptions and performance implications.\n",
       "\n",
       "Therefore, the documentation is 'good' but with room for improvement.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lionagi.core.collections.model import iModel\n",
    "from lionagi.core.session.branch import Branch\n",
    "\n",
    "chat_model = iModel(model=\"gpt-4o\", temperature=0.5)\n",
    "branch = Branch(imodel=chat_model)\n",
    "\n",
    "format_model = iModel(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "formatter = format_model.format_structure\n",
    "\n",
    "result = await branch.direct(\n",
    "    instruction=\"please very very detail devaluate the documentation using various criteria in your knowledge\",\n",
    "    context=text,\n",
    "    reason=True,\n",
    "    confidence=True,\n",
    "    allow_extension=True,\n",
    "    select=True,\n",
    "    select_choices=[\"good\", \"bad\", \"neutral\"],\n",
    "    formatter=formatter\n",
    ")\n",
    "\n",
    "result.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ln_id</th>\n",
       "      <th>message_type</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>role</th>\n",
       "      <th>content</th>\n",
       "      <th>metadata</th>\n",
       "      <th>sender</th>\n",
       "      <th>recipient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ccbc1c7585b7e375bf06631b82846a52</td>\n",
       "      <td>System</td>\n",
       "      <td>2024-09-06T16:54:50.404168</td>\n",
       "      <td>system</td>\n",
       "      <td>{'system_info': 'You are a helpful assistant.'}</td>\n",
       "      <td>{'last_updated': {'recipient': '2024-09-06T16:...</td>\n",
       "      <td>system</td>\n",
       "      <td>f5f86b60de359fa325bb4fb9b8d69652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e2ab3a60e0b2bebe5697e18e3c94f0df</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>2024-09-06T16:54:50.407135</td>\n",
       "      <td>user</td>\n",
       "      <td>{'instruction': '\n",
       "        ## Task Instructions...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-09-06T16:54:...</td>\n",
       "      <td>user</td>\n",
       "      <td>f5f86b60de359fa325bb4fb9b8d69652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78472abcc7b0dbf8c2c71dd9f45526b6</td>\n",
       "      <td>AssistantResponse</td>\n",
       "      <td>2024-09-06T16:54:59.125147</td>\n",
       "      <td>assistant</td>\n",
       "      <td>{'assistant_response': '```json\n",
       "{\n",
       "    \"answer\"...</td>\n",
       "      <td>{'last_updated': {'sender': '2024-09-06T16:54:...</td>\n",
       "      <td>f5f86b60de359fa325bb4fb9b8d69652</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ln_id       message_type  \\\n",
       "0  ccbc1c7585b7e375bf06631b82846a52             System   \n",
       "1  e2ab3a60e0b2bebe5697e18e3c94f0df        Instruction   \n",
       "2  78472abcc7b0dbf8c2c71dd9f45526b6  AssistantResponse   \n",
       "\n",
       "                    timestamp       role  \\\n",
       "0  2024-09-06T16:54:50.404168     system   \n",
       "1  2024-09-06T16:54:50.407135       user   \n",
       "2  2024-09-06T16:54:59.125147  assistant   \n",
       "\n",
       "                                             content  \\\n",
       "0    {'system_info': 'You are a helpful assistant.'}   \n",
       "1  {'instruction': '\n",
       "        ## Task Instructions...   \n",
       "2  {'assistant_response': '```json\n",
       "{\n",
       "    \"answer\"...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'last_updated': {'recipient': '2024-09-06T16:...   \n",
       "1  {'last_updated': {'sender': '2024-09-06T16:54:...   \n",
       "2  {'last_updated': {'sender': '2024-09-06T16:54:...   \n",
       "\n",
       "                             sender                         recipient  \n",
       "0                            system  f5f86b60de359fa325bb4fb9b8d69652  \n",
       "1                              user  f5f86b60de359fa325bb4fb9b8d69652  \n",
       "2  f5f86b60de359fa325bb4fb9b8d69652                              user  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch.to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
